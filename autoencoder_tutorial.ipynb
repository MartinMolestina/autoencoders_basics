{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c48476-ac57-49cb-abb5-f10b6436de54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "803920dc-0b73-484a-80a8-80181f04df19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf  \n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.random import randn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb014025-c91e-4bdd-ae2b-ad4a603648fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# El numero de neuronas de la imagen codificada\n",
    "layer1_dim = 512\n",
    "layer2_dim = 256\n",
    "encoding_dim = 128 \n",
    "\n",
    "# La imagen de input\n",
    "input_img = keras.Input(shape=(784,))\n",
    "# ecoded es la primera capa e la red neuronal\n",
    "encoded = keras.layers.Dense(layer1_dim, activation='relu')(input_img)\n",
    "# encoded ahora es la segunda capa e la red neuronal\n",
    "encoded = keras.layers.Dense(layer2_dim, activation='relu')(encoded)\n",
    "# encoded es la ultima representacion codificada de la imagen en dimensiones menores\n",
    "encoded = keras.layers.Dense(encoding_dim, activation='relu')(encoded)\n",
    "\n",
    "# decoded amplia las dimensiones a layer2_dim\n",
    "decoded = keras.layers.Dense(layer2_dim, activation='relu')(encoded)\n",
    "# decoded amplia las dimensiones a layer21_dim\n",
    "decoded = keras.layers.Dense(layer1_dim, activation='relu')(decoded)\n",
    "# \"decoded\" es la reconstruccion de la imagen a partir de la informacion codificada\n",
    "decoded = keras.layers.Dense(784, activation='sigmoid')(decoded)\n",
    "\n",
    "# Este es el modelo desde la imagen -> codificacion -> imagen reconstruida\n",
    "autoencoder = keras.Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2e6a62d-e201-48db-9968-c0ea7f8e8203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Este modelo codifica la imagen original \n",
    "encoder = keras.Model(input_img, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7290d4dc-ba43-4ebd-938c-32768f2fe3bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-279ef35d5a41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdecoder_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Se crea el modelo de decodificador\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "# El input es la imagen codificada de dim=128\n",
    "encoded_input = keras.Input(shape=(encoding_dim,))\n",
    "# Se recupera la ultima capa del modelo completo de autoencoder\n",
    "decoder_layer = autoencoder.layers[-3]\n",
    "# Se crea el modelo de decodificador\n",
    "decoder = keras.Model(encoded_input, decoder_layer(encoded_input))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f32a35db-1ea8-4893-877d-d7c0fcaeaabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2007d64a-9ca9-4760-b819-7c4b6dfd3c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c079b881-72c4-47e9-865d-230cbf078e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6000/6000 [==============================] - 83s 1ms/step - loss: 0.1434 - val_loss: 0.0968\n",
      "Epoch 2/10\n",
      "6000/6000 [==============================] - 8s 1ms/step - loss: 0.0951 - val_loss: 0.0904\n",
      "Epoch 3/10\n",
      "6000/6000 [==============================] - 8s 1ms/step - loss: 0.0904 - val_loss: 0.0896\n",
      "Epoch 4/10\n",
      "6000/6000 [==============================] - 8s 1ms/step - loss: 0.0877 - val_loss: 0.0873\n",
      "Epoch 5/10\n",
      "6000/6000 [==============================] - 8s 1ms/step - loss: 0.0861 - val_loss: 0.0857\n",
      "Epoch 6/10\n",
      "6000/6000 [==============================] - 8s 1ms/step - loss: 0.0847 - val_loss: 0.0837\n",
      "Epoch 7/10\n",
      "6000/6000 [==============================] - 8s 1ms/step - loss: 0.0833 - val_loss: 0.0832\n",
      "Epoch 8/10\n",
      "6000/6000 [==============================] - 8s 1ms/step - loss: 0.0825 - val_loss: 0.0820\n",
      "Epoch 9/10\n",
      "6000/6000 [==============================] - 8s 1ms/step - loss: 0.0815 - val_loss: 0.0816\n",
      "Epoch 10/10\n",
      "6000/6000 [==============================] - 8s 1ms/step - loss: 0.0805 - val_loss: 0.0819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5fb0227a90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=10,\n",
    "                batch_size=10,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3828e03b-0d70-4cd8-a99d-462c35d7f10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8afe0102-ef96-41c3-ac95-969c00ede554",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 256 into shape (28,28)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-b0606d8d0e88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Display reconstruction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded_imgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_xaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 256 into shape (28,28)"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGkAAADkCAYAAACbrAo8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAPAUlEQVR4nO2dWWybV3qGn08ktZCUSEqyrV2W7NiO69iZGaWeIEhbu+1kMhdxgRpoHBSdKVIEKDot0F41yEWB9KbLxQAFWjRBEbS98UyTm2Tg1k3QtBgYGGfiJIWVsbyNHGuxtZGiRIrifnrBpbSthbIpk0f8HuCHyH8hD/XwkEdH7//9YoxBqW0aqt0AZXNUkgWoJAtQSRagkizAWe0G3I+I1NNwc8EYs2uznbQnVZfb5eykkixAJVmASrIAlWQBKskCVJIFqCQLUEkWoJIsQCVZgEqyAJVkATU3C75VPB4PPp8Pr9dLZ2cnAMlkEmMMmUyGdDpNMBgkkUiQSqXIZrPE43EymUyVW14+1kvatWsXR48eZWhoiOeff55sNks4HCadTpNKpYhGo1y4cIFQKMTS0hLxeJz5+XlWVlaq3fSysV6S3+/n4MGD9Pf309vbizEGn89X7EWxWIxYLEY4HGZ5eZlEIsHs7CyRSOShnzObzZJOp0mn04RCIWKxWLGnbgfWS9q/fz9nzpwhEAjQ1dWFiJDNZovbM5kML7zwAplMhtXVVVKpFNPT0ywvLz/0c2YyGRYXF4lGo3z00UeMj48zNTVFKBSqxEt6AOslJRIJFhcXMcbgcDgASKVSiAgul4uGhgaampoQETweD5D7Jbe1tZHJZMhkMjgcjuKx92OMwRhTFO9wODDG0NraSjQapbu7m0gkwsLCwra9RuslXblyhbfeeotAIEBfXx+JRIKZmRmcTiddXV14PB76+vrwer3s378fn8/H7t27cblcLC8vE4vF8Hq9tLa2PvDYhcFHJpMpfjz6/X4cDgeZTIZkMkk4HKazs5NgMMidO3e25TVaLykajTIxMcHS0hLJZJJ4PF6UFIvF8Hg8JJNJ2traaGxsxO/309HRgdvtJhgMEolE8Pv9pNPpBx67ICmVShEOh3G5XPj9fhobG2loaMDlctHS0kJjYyNO5/b9Kq2XVPjidjgcNDY2ks1mSSaTiEjxl9nU1ITT6SQQCNDS0kJfXx9tbW1MT0+zsLBAd3c3XV1dDzx2NpsllUoVxe/Zs4fXX3+dvXv34na7McYQDoeZn59ndXV1216j9ZJSqVRZoyoRYXZ2lsbGRsLhMH6/n6mpKYLBIMFgcM3vFGMMqVSKZDJJMBhkdXWVeDxONpu9Z/S4vLy8bSM72AGSysUYQzweJ5lMcvv2baanp4v379y5QzAYXPO4bDaLx+NheHiYoaEh/H4/TU1NzM/PEw6H+eKLL7h48SKzs7Pb1va6kQQUBwH3v+sLf0uth9PppKOjg87OTpqbm3E4HKysrLC4uMjc3BwzMzP6cVctnE4nLS0t9Pf3c/r0aQYGBggEAiSTSS5cuMCNGzf46quvWFlZ2dZpJpW0AQ0NDbS0tNDR0cHRo0fp6+ujpaWFaDTKrVu3GBsbIxQKbev3EaikDQkEAhw/fpxDhw7R3t5OS0tLcT4wGAwyNzdHIpHY9nbovyo2wOv1cvjwYZ544glaW1tpbGwklUqRSCRYWloiHA5vey8C7Ulr4na7aW9v58CBAzz33HN0dXXR1NREJBLh/PnzTExMcOPGDRYWFh5LT1JJa+B2u+nr6+PAgQM8++yztLW14XQ6mZ+f5/z581y7do3r168/0iTtVlBJa+DxeBgcHKSrqwun00k6nWZ+fp6pqSnu3r3L3NwcyWTysbVHJa2Bz+fj0KFDDA4OFr+HxsfHi8vk5OSac33bhUoqQURoaGjA7XbT09NDe3s7ACsrK1y9epXx8XFWV1fJZDI8ztIKKqmEwsx2Z2cnhw8fprOzE2MMCwsLfPjhh9y6dYtwOHzPPxUfByqphLa2Nvbs2UNvb29xji4cDhMMBotzdY/zY66ASiphaGiIkydPcuzYMfbt20ckEmFsbIwrV65w7do15ubmqpIyUklAU1MTzc3N7Nmzh+HhYbq6umhoaCAejzM5Ocndu3dJJBJVi4GpJKC7u5uhoSFOnDjB6dOncTqdJJNJJiYmeP/995mamtpwlny7qetpIRHB4XDQ3t7O4OAg3d3d+P1+XC4X0WiUcDjMzMwMoVCoqmHKuu5Jzc3NNDU1cfz4cV555RW6u7txOByEw2FGR0e5fPlycWahGgOGAnUtyev14vP56Onpob+/H6/XSzabJRaLFWcWotEo8Xi8qu2sS0mFj7kXX3yREydOcOTIEXbv3l2Mg42OjvLuu+8yMzPzWKd/1qMuJTU0NOB0Ount7eXYsWN0d3fT3NxcjCPPzs5y69YtlpaWHvsfrmtRd5JEhLa2NlpbWxkYGGDv3r20tLQAcP36dc6dO8fVq1eZmZkhkUiopGpQiBv7/X58Ph9+v78Ygpybm+Py5ctMTk4SiURqQhDUkSQRwev14vF4OHXqFEePHuWpp54CclHlsbExLly4wOjoKNFo9LFOoG5GXUlyu934fD5GRkY4efIkgUAAgOnpaT755BNGR0eZmJiomR5UoG4kOZ1ODh48yMDAAP39/cUJVIDFxUXGx8cJhUI11YMK1JWkffv28eSTT9LT03PPWRRLS0tMTk6qpGrhcDjo6Oigvb2dI0eOcOTIEfx+f7WbtSV2vCSn00lPTw+9vb0888wzPP300zQ3N1e7WVtix0sq9KRdu3bhdruLZ/9B7izBZDJZPE2z1gYMBXa8JJfLRX9/P8PDw/h8vuJgASASibC8vFw84bmak6gbseMlQW74LSLF+6urqySTScbGxhgfH+fmzZtEo9HHEnR8GOpCUimFYEkoFOLs2bOcO3eu2KNqcWQHdSCpMN3jcrn4/PPPmZmZYXZ2luXlZW7fvk04HK6ZObr1kFp791S6eLuI0NzcXDzXqHDmeDabZWVlhXg8Xs0e9JkxZmSznXZ8TzLGFM/Ce5QqKNWkFiUtUGbl+R3AYDk71dzHnfIgdZ0WsgWVZAEqyQJUkgWoJAtQSRagkixAJVmASrIAlWQBKskCVJIFqCQLUEkWoJIsQCVZgEqyAJVkASrJAlSSBagkC1BJFqCSLEAlWYBKsgCVZAEqyQJUkgWoJAtQSRagkixAJVmASrIAlWQBKskCNpUkIu+IyJyIfLnOdhGRvxORmyJyWUS+XrLtuyJyI798t5INryuMMRsuwK8AXwe+XGf7d4D/AAT4JvBJfn07MJ7/GcjfDmz2fLo8uGzak4wxPwFCG+xyCvhXk+Mi4BeRbuAF4CNjTMgYswh8BHz7Id5HdU8l6jj0ApMl96fy69Zb/wAi8hrwGoDH4/nGoUOHKtCs2uezzz5bMMbs2my/mii2YYx5G3gbYGRkxFy6dKnKLXo8iEhZRUUqMbqbBvpL7vfl1623XtkilZD0AfB7+VHeN4ElY8xd4D+Bb4lIQEQCwLfy65QtsunHnYicBX4N6BSRKeAvABeAMeYfgX8nN8K7CcSA389vC4nIXwKf5h/qTWPMRgMQZR02lWSMObPJdgP80Trb3gHeebimKQV0xsECVJIFqCQLUEkWoJIsQCVZgEqyAJVkASrJAlSSBagkC1BJFqCSLEAlWYBKsoCyJInIt0XkWj5b9+drbP+BiPxvfrkuIuGSbZmSbR9UsO11Qzn/mXUAfw/8JrnEz6ci8oEx5kphH2PMn5bs/8fA10oeYtUY83TFWlyHlNOTfhm4aYwZN8YkgR+Sy9qtxxngbCUap+QoR9JW8nODwBDwccnqZhG5JCIXReS3Hrah9Uylc3cvA+8ZYzIl6waNMdMiMgx8LCKjxphflB5UGo4cGBiocJPsp5yetJX83Mvc91FnjJnO/xwH/od7v68K+7xtjBkxxozs2rVpoLPuKEfSp8ATIjIkIo3kRDwwShORQ+SC+T8tWRcQkab87U7gOeDK/ccqG1NOpCstIt8nF2x0AO8YY34uIm8Cl4wxBWEvAz80915/7kngLRHJkntD/FXpqFApj5q7pl+dZcHLuoSpzjhYgEqyAJVkASrJAlSSBagkC1BJFqCSLEAlWYBKsgCVZAEqyQJUkgWoJAtQSRagkiygUuHI74nIfEkI8g9KtmlhwkekIuHIPD8yxnz/vmPbyZW5GQEM8Fn+2MWKtL5O2I5wZClamLACVDIc+dv5GqzviUghAlbWsSLyWj5AeWl+fr7MptcPlRo4/BjYa4w5Sq63/MtWDtbc3cZUJBxpjAkaYxL5u/8EfKPcY5XNqUg4Ml8Yt8BLwFj+thYmrACVCkf+iYi8BKTJVT7+Xv5YLUxYATQcWUU0HLmDUEkWoJIsQCVZgEqyAJVkASrJAlSSBagkC1BJFqCSLEAlWYBKsgCVZAEqyQJUkgVUKhz5ZyJyJZ8W+q98SbXCNq0c+YhUKhz5BTBijImJyB8CfwP8Tn6bVo58RCoSjjTG/LcxJpa/e5FcKkipEBWtHJnnVXLXQi+waeVIDUduTEUrR4rI75LLff9qyepNK0fef8XmSrZpJ1CxypEi8hvAG8BLJUHJsipHKhtTqXDk14C3yAmaK1mvlSMrQKXCkX8LeIF3RQRgwhjzElo5siJoOLKKaDhyB6GSLEAlWYBKsgCVZAEqyQJUkgWoJAtQSRagkixAJVmASrIAlWQBKskCVJIFqCQLqFQ4sklEfpTf/omI7C3Z9np+/TUReaGCba8bNpVUEo58ETgMnBGRw/ft9iqwaIzZD/wA+Ov8sYfJZSJ+iVwxwn/IP56yBSpVOfIU/1/j7j3g1yUXdjhF7oqZCWPMLeBm/vGULVBO7m6tcOTx9fbJB1eWgI78+ov3Hbtm5UjyV2wGEiLyZVmtt5+D5exU6ctqPxSl4UgRuVROOGMnICJlJW4qFY4s7iMiTsAHBMs8VtmESl1W+wOgUPP7NPBx/srNHwAv50d/Q8ATwM8q0/Q6whiz6QJ8B7gO/AJ4I7/uTXKJVYBm4F1yA4OfAcMlx76RP+4a8GIZz/VaOW3aCUu5r7XmwpHKg+iMgwWoJAuoKUmbTT/tFETkHRGZK/fvwZqRVOb0007hn9nCNTtqRhKPduESqzDG/IRc/fSyqCVJWz03t26oJUnKOtSSJJ1CWodaklTO9FNdUjOSjDFpoHBu7hjwb8aYn1e3VduDiJwFfgocFJEpEXl1w/11Wqj2qZmepKyPSrIAlWQBKskCVJIFqCQLUEkW8H9oXX+NKWWAhQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1440x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n =16 # How many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # Display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab39dd0c-bfea-47a9-a9bd-f6dcc46dab6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.14715768  1.88422051  1.04635292  4.99034371  6.05323658  8.38141325\n",
      "   1.45822883  4.28619125  0.79091193  3.19669283  6.0772925  12.76231036\n",
      "   2.32550662  4.3105003   0.1330121   4.85289138  0.56282662  0.47660405\n",
      "   3.92270483  1.21935589  2.46494921  1.323418    6.67362272  0.4666111\n",
      "   1.05759705  1.76660746  2.05034463  5.41509075 17.13444997  3.44047385\n",
      "   2.54108491  9.72975258  4.97849382  2.95837611  8.73640328  3.13001631\n",
      "   1.80481842  3.0935252   1.97944582  2.40271192  5.32649559  5.268893\n",
      "  12.63960073  1.75444273  5.32999363  7.35180459  2.88356129  0.91751967\n",
      "   3.06864156  6.33982652  9.40201623  1.07463885  0.81046337 13.140547\n",
      "   2.49738795  3.01984516 10.10274214 10.84202091  5.14523667  5.50279018\n",
      "   1.73137589  7.61179315  6.75346437  1.58244137  1.6596643   0.10382156\n",
      "   1.3981228   2.72484713  0.93562638  7.01704258  3.50833973  5.84016949\n",
      "   3.63880061  2.25339416  1.066107    1.10023249  0.65145354  7.13536382\n",
      "   2.33787442  2.91519813  0.60088799  3.06782525  0.47713813  2.37596188\n",
      "   0.45005435  6.61094276  2.83676361  1.98920047  0.85312921  1.63391516\n",
      "  11.71221185  3.73195792  4.87778195  1.22628078  0.26627655  7.94279987\n",
      "   4.84405943  7.15606499  1.18075059  3.18626502  1.98370541  0.14999539\n",
      "  11.60058679  1.20160501  4.69621881  0.08498214 11.24877182  1.22061513\n",
      "   2.90940882  0.50286683  4.74917167  6.02146583  1.36861402  0.28553845\n",
      "   1.8535315   2.38497147  4.20763992  1.59256362  3.25571852  2.98517749\n",
      "   7.54754477  3.00593997  0.45981779  7.11851807  1.82215224  7.70977488\n",
      "   0.08947916  5.99805427]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 256 into shape (28,28)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-fe3a70a9e733>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_noise_img\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdecoded_random\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_noise_img\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 256 into shape (28,28)"
     ]
    }
   ],
   "source": [
    "# Se decodifica un input aleatorio de valores\n",
    "\n",
    "random_noise_img = randn(encoding_dim).reshape(1,encoding_dim)\n",
    "print(abs(random_noise_img*5))\n",
    "decoded_random = decoder.predict(abs(random_noise_img*5))\n",
    "plt.imshow(decoded_random.reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7b4dcdd-0a81-4ea7-b08f-474df69fdb11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.77583355 0.         0.         2.22363234 0.\n",
      "  1.35624993 1.42748427 0.         0.         0.         1.09179819\n",
      "  0.         0.55129808 0.30600104 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.33767539 0.         1.8754586  0.         0.         0.\n",
      "  0.17613022 0.87587333 0.         1.8126626  0.74018776 0.\n",
      "  0.         0.         1.91627705 0.48437059 0.         0.\n",
      "  0.         0.         0.         0.24327506 1.08609033 0.\n",
      "  1.38692892 0.         0.         1.18196535 0.         1.3124578\n",
      "  0.         0.         0.         0.05172423 0.93832016 0.\n",
      "  0.63123721 0.94754636 0.         1.30081403 2.11264253 0.564089\n",
      "  0.         0.         0.         0.         0.82021701 0.\n",
      "  0.         2.18232751 0.         1.42227173 0.         0.98003292\n",
      "  1.51892424 0.         2.32537556 0.26078194 0.         0.\n",
      "  1.49077034 0.         0.06179525 1.38445282 0.27145216 0.\n",
      "  2.3006165  2.61481643 0.60629386 0.         0.         0.\n",
      "  0.29859802 0.         0.         2.96401906 0.         0.\n",
      "  0.         0.         0.03348011 0.         1.93450558 0.\n",
      "  0.         1.10486937 0.         0.         0.         0.\n",
      "  0.14380187 0.         0.         0.         0.         0.\n",
      "  1.38850915 1.28593481 0.         1.31341362 0.         0.59076059\n",
      "  0.81744027 0.        ]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 256 into shape (28,28)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-eebb7e9f26ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavrg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mavrg_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavrg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavrg_num\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 256 into shape (28,28)"
     ]
    }
   ],
   "source": [
    "avrg =[]\n",
    "for a,b in zip(encoded_imgs[0], encoded_imgs[2]):\n",
    "    avrg.append((a+b)/2)\n",
    "avrg = np.array(avrg).reshape(1,encoding_dim)\n",
    "print(avrg)\n",
    "avrg_num = decoder.predict(avrg)\n",
    "plt.imshow(avrg_num.reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac2978b-b590-46de-9a3d-344a8628de37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed2e57e-d3c7-41af-81ed-9beb1546a5d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
