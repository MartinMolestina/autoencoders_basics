{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "399c1785-e825-4103-a578-3b1b7cf67e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU's disponibles:  1\n"
     ]
    }
   ],
   "source": [
    "# Librerias requeridas\n",
    "import tensorflow as tf  \n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Prueba si TF reconoce el GPU\n",
    "print(\"GPU's disponibles: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31f10688-5d3c-4468-b4e5-0ed2a3f136e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa el dataset mnist\n",
    "(x_train, y_train),(x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normaliza los valores de los pixeles entre 0-1\n",
    "x_train = x_train/255.0  \n",
    "x_test = x_test/255.0  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "356c5e28-fb70-4e29-8248-f2c8acef4c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4e3c071160>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Muestra una de las imagenes del dataset de forma aleatoria\n",
    "plt.imshow(x_train[random.randint(0, len(x_train))], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "22f1b577-54f7-4a21-9970-8c0229f17f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# La primera capa de la Red Neuronal tiene que ser de 784 neuronas (28*28)\n",
    "encoder_input = keras.Input(shape=(28, 28, 1), name='img')\n",
    "x = keras.layers.Flatten()(encoder_input)\n",
    "# Se reduce a 64 neuronas \n",
    "encoder_output = keras.layers.Dense(64, activation=\"relu\")(x)\n",
    "\n",
    "# se define el modelo\n",
    "encoder = keras.Model(encoder_input, encoder_output, name='encoder')\n",
    "\n",
    "# Se define el decodificador\n",
    "decoder_input = keras.layers.Dense(64, activation=\"relu\")(encoder_output)\n",
    "# Layer de output de misma dimension que el input\n",
    "x = keras.layers.Dense(784, activation=\"relu\")(decoder_input)\n",
    "# Se ajusta a la forma de los pixeles de la imagen\n",
    "decoder_output = keras.layers.Reshape((28, 28, 1))(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f15a6777-6d39-4047-9c3a-75a0c4b4b340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "img (InputLayer)             [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 784)               50960     \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 105,360\n",
      "Trainable params: 105,360\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# se define el optimizador\n",
    "opt = tf.keras.optimizers.Adam(lr=0.001, decay=1e-6)\n",
    "\n",
    "# Se define el autoencoder desde input hasta output\n",
    "autoencoder = keras.Model(encoder_input, decoder_output, name='autoencoder')\n",
    "autoencoder.summary()\n",
    "\n",
    "autoencoder.compile(opt, loss='mse')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "67a87d3d-6eb0-4291-8108-387e6745b775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3375/3375 [==============================] - 4s 1ms/step - loss: 0.0106 - val_loss: 0.0104\n",
      "INFO:tensorflow:Assets written to: models/AE-1.model/assets\n",
      "3375/3375 [==============================] - 4s 1ms/step - loss: 0.0102 - val_loss: 0.0100\n",
      "INFO:tensorflow:Assets written to: models/AE-2.model/assets\n",
      "3375/3375 [==============================] - 4s 1ms/step - loss: 0.0100 - val_loss: 0.0100\n",
      "INFO:tensorflow:Assets written to: models/AE-3.model/assets\n",
      "3375/3375 [==============================] - 4s 1ms/step - loss: 0.0098 - val_loss: 0.0099\n",
      "INFO:tensorflow:Assets written to: models/AE-4.model/assets\n",
      "3375/3375 [==============================] - 4s 1ms/step - loss: 0.0098 - val_loss: 0.0097\n",
      "INFO:tensorflow:Assets written to: models/AE-5.model/assets\n"
     ]
    }
   ],
   "source": [
    "# Se entrena el modelo en 5 epochs y batches de 16 imagenes\n",
    "\n",
    "epochs=5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    history = autoencoder.fit(\n",
    "      x_train,\n",
    "      x_train,\n",
    "      epochs=1, \n",
    "      batch_size=16, validation_split=0.10\n",
    "        )   \n",
    "    autoencoder.save(f\"models/AE-{epoch+1}.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "11d223ff-fba9-4ebb-9203-29880858cb18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64,)\n",
      "[0.83867794 1.2491418  1.3113685  2.2947154  1.1435788  2.6750157\n",
      " 0.6586572  0.8805635  0.92221445 1.2250199  1.7284172  1.3305552\n",
      " 0.01087612 1.0941266  2.016294   1.0072619  1.3780513  1.7237071\n",
      " 0.60228044 1.1082274  0.31841505 0.81731415 2.6309125  1.5924144\n",
      " 1.2319001  0.6324132  0.07555449 0.80470604 1.2298982  0.05786511\n",
      " 1.6724875  0.7536601  1.7581221  1.0924345  0.         1.8184744\n",
      " 1.2780976  1.5051448  1.0484746  0.         0.6683581  0.75636876\n",
      " 0.45408103 1.1076896  0.80110276 0.         1.5009041  1.2352104\n",
      " 0.6796894  0.5467358  2.3804157  0.09047517 1.9284433  1.3974358\n",
      " 0.5879513  0.9887193  0.8731303  1.7986318  0.53575796 2.0789847\n",
      " 2.429594   0.32133776 1.2636945  1.4562923 ]\n"
     ]
    }
   ],
   "source": [
    "example = encoder.predict([ x_test[0].reshape(-1, 28, 28, 1) ])\n",
    "print(example[0].shape)\n",
    "print(example[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "77684fe9-c7cd-4b88-9fde-3c0086d09a53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4e3c19c670>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ae_out = autoencoder.predict([ x_test[0].reshape(-1, 28, 28, 1) ])\n",
    "img = ae_out[0]  # predict is done on a vector, and returns a vector, even if its just 1 element, so we still need to grab the 0th\n",
    "plt.imshow(ae_out[0], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22ef8b1-e4b9-480a-a4c5-0f44d96112d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc-autonumbering": true,
  "toc-showcode": true,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
